## 当前遇到的问题
paddle的繁体字识别效果不好，
需要根据文本重新生成文本识别的图片，然后再重新训练吧。
目前看有几个比较好的资料库。
https://textrecognitiondatagenerator.readthedocs.io/en/latest/tutorial.html#generating-chinese-data

https://github.com/Belval/TextRecognitionDataGenerator

https://github.com/oh-my-ocr/text_renderer

https://github.com/JarveeLee/SynthText_Chinese_version  这个是基于图片的生成的文字，意义不太大。


OCR文本生成




## 繁体转换简体
ls *.md | xargs -i opencc -i {} -o {}.txt -c t2s


cp -r 1956年1* ../../rmrbtxt/

cp 194* ../../

ls 7z | xargs -i 7zr x {} -y 

find -name *.txt | xargs rm -rf 


find -name *.txt | xargs cat {}  > all.txt

人民日报语料处理
```
cd /home/liukun/ocr/Corpus/rmrb/7z
cp 194* ../../rmrbtxt/ 文字
 ```

### 生成图片
trdg  -l cn -c 1000 -w 10 --dict /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/dicts/merge_ch.txt --font /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/fonts/cn/fzxbs_gbk.ttf 

trdg  -l cn -c 10 -w 15 -i /home/liukun/ocr/Corpus/rmrbtxt/1946年05月/1946-05-15_国民党军猛攻廿三天未逞_民主联军坚守四平街_中美报纸责国民党挑动内.txt --dict /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/dicts/merge_ch.txt --font /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/fonts/cn/fzxbs_gbk.ttf 



trdg  -l cn -c 10 -w 15  -e png --rk -na 2 -i /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/texts/all_ch.txt  --font /home/liukun/ocr/Corpus/TextRecognitionDataGenerator/trdg/fonts/cn/fzxbs_gbk.ttf 


# 文本检测之训练模型
CTPN的方法训练ocr时，
loss在百以上时，acc基本上时0。
当loss降到个位数时，acc才有1%左右的数据集。

训练数据过程中，出现了png图片不存在的情况，因为切割图片对应的是空白的，需要写点代码解决这些问题
```
import os
current_dir="/home/aistudio/OCRDataset/train2"
file_name_set=set( [fn for fn in  os.listdir(current_dir) ])
del_file_name_lists=[]
with open('labels.txt','r') as fl:
    with open('clear_labels.txt','w') as cfl:

        myline=fl.readline()
        while myline:
            file_name=myline.split('\t')[0]
            if file_name not in file_name_set:
                print(file_name)
            else:
                cfl.write(myline)
            myline=fl.readline()
```


# 临时存放语料数据
https://rmfygg.court.gov.cn/web/rmfyportal/noticeinfo?noticeTypeCode=66

https://rmfygg.court.gov.cn/web/rmfyportal/noticeinfo?noticeTypeCode=66

# 
图片生成的训练的数据集，在val验证数据集上的效果还是可以的
eval model:: 100%|██████████████████████████████| 10/10 [00:10<00:00,  1.05s/it]
[2023/02/28 12:14:56] ppocr INFO: cur metric, acc: 0.9627999961488, norm_edit_dis: 0.9963466333812468, fps: 3109.2419781588987
[2023/02/28 12:14:56] ppocr INFO: save best model is to ./output/rec/chch/best_accuracy
问题在于使用训练的模型，测试国务院公告的图片时，效果非常的差。

全国人民代表大会常务委员会
识别的结果如下所示。
result: 全阻入民代禿大妄惋多袋衰得·    0.4964383542537689

https://github.com/ssliar/Enhanced-Fonts-style-transfer 

https://arxiv.org/pdf/2104.03064.pdf


https://github.com/liweileev/FET-GAN

https://www.cnblogs.com/Stareven233/p/16649550.html

https://github.com/deepkyu/multilingual-font-style-transfer

以上是方案字体风格迁移的方案。

目前的方案有有两个：
1. 在国务院的公告上进行标注，先标注256条，然后微调，看一下训练结果如何。
2. 找到一个神经网络可以生成国务院公告风格的文字图片。然后再进行训练。