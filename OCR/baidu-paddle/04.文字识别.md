目前采用用了,人工标注的数据，大概340条，在百度的ocr识别模型上跑，效果不高，acc在50% 左右，fine-tune数据太少，根本没有什么效果。甚至是负面的效果。

人工校验汉字，然后组成新的句子，进入ocr图片进行训练吧，如果可以提升ocr的效果，那么就认为是可行的。


关于自动生成字体的问题，对比学习和gan神经网络。

# 2023-03-07 
把每个字符切割，随机生成句子，然后训练一下数据能否提升效果。
最开始的准确率比较低：
epoch: [1/600], global_step: 10, lr: 0.000003, acc: 0.027344, norm_edit_dis: 0.292343, CTCLoss: 73.472076, SARLoss: 6.741199, loss: 80.212234, avg_reader_cost: 0.56235 s, avg_batch_cost: 2.18094 s, avg_samples: 128.0, ips: 58.69021 samples/s, eta: 4 days, 3:13:36
观点：看来随机生成句子，识别ocr时，丢失了语义的信息，目前看起来主要是用于识别文字，用于训练backbone部分的特征抽取。


主测试数据集上训练的数据非常好，但是不能经过实践检验，应该是过拟合了.


希望验证，通过加入合成的图片，是否可以提高识别的准确度？
采用的方法是，查看val数据的涉及的所有汉字，然后加到汉字库中（383个，实际加入183的太费人工了），重新生成校验数据，
val.txt的图片，之前训练模型的ctc是0.13 ，加入新的汉字后acc提高到到0.20，

acc

下图
2023/03/07 19:42:59] ppocr INFO: load pretrain successful from /home/aistudio/work/output/v3_chinese_cht_mobil/best_accuracy
[2023/03/07 19:42:59] ppocr INFO: metric in ckpt ***************
[2023/03/07 19:42:59] ppocr INFO: is_float16:False
eval model:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.21s/it]
[2023/03/07 19:43:07] ppocr INFO: metric eval ***************
[2023/03/07 19:43:07] ppocr INFO: acc:0.22105260831025175
[2023/03/07 19:43:07] ppocr INFO: norm_edit_dis:0.8275820946928321
[2023/03/07 19:43:07] ppocr INFO: fps:16.32460649029274

但是还是达不到paddleocr的原始繁体字识别效果acc=0.515

[2023/03/07 19:54:34] ppocr INFO: metric in ckpt ***************
[2023/03/07 19:54:34] ppocr INFO: is_float16:False
eval model:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.19s/it]
[2023/03/07 19:54:43] ppocr INFO: metric eval ***************
[2023/03/07 19:54:43] ppocr INFO: acc:0.5157894193905874
[2023/03/07 19:54:43] ppocr INFO: norm_edit_dis:0.9203884438106642


生成的数据越多，效果越差，应该是正确的汉字少，过拟合了。

## 目前获的信息
1. 通过切割每个单词的图片，然后训练组合成一个字符串，是可以提高ocr的准确度的，但是需要大量的人工，目前两天的时间大概标注了243个单词，主要是一个一个的拆分。
2. 随机生成图像数据集，非常容易过于饱和，此时在paddle原有的ocr上进行调试，5万条数据，acc 13%，增加了50个左右的字之后，acc提升到20%，生成10
3. 万条数据后，acc的值反而下降到8%，观察结果发现，过拟合的训练，把原来的识别正确的字符，识别到新加的字符上了。
今天大概看了
- 对比学习和gan对抗神经网络的视频
gan用于做字体切换知识储备
对比学习，非常有意思，可以通过无监督学习生成特征，如果我把单个图片的按照字符切割，通过对比学习，可以学习到每张图片的特征向量，
然后通过聚类，找到中心点去确认每个单词的图片特征，快速分校验ocr的问题。

明天要看cc-gan看看能否生成有用的字体。