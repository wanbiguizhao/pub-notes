目前采用用了,人工标注的数据，大概340条，在百度的ocr识别模型上跑，效果不高，acc在50% 左右，fine-tune数据太少，根本没有什么效果。甚至是负面的效果。

人工校验汉字，然后组成新的句子，进入ocr图片进行训练吧，如果可以提升ocr的效果，那么就认为是可行的。


关于自动生成字体的问题，对比学习和gan神经网络。

# 2023-03-07 
把每个字符切割，随机生成句子，然后训练一下数据能否提升效果。
最开始的准确率比较低：
epoch: [1/600], global_step: 10, lr: 0.000003, acc: 0.027344, norm_edit_dis: 0.292343, CTCLoss: 73.472076, SARLoss: 6.741199, loss: 80.212234, avg_reader_cost: 0.56235 s, avg_batch_cost: 2.18094 s, avg_samples: 128.0, ips: 58.69021 samples/s, eta: 4 days, 3:13:36
观点：看来随机生成句子，识别ocr时，丢失了语义的信息，目前看起来主要是用于识别文字，用于训练backbone部分的特征抽取。


