目前采用用了,人工标注的数据，大概340条，在百度的ocr识别模型上跑，效果不高，acc在50% 左右，fine-tune数据太少，根本没有什么效果。甚至是负面的效果。

人工校验汉字，然后组成新的句子，进入ocr图片进行训练吧，如果可以提升ocr的效果，那么就认为是可行的。


关于自动生成字体的问题，对比学习和gan神经网络。

# 2023-03-07 
把每个字符切割，随机生成句子，然后训练一下数据能否提升效果。
最开始的准确率比较低：
epoch: [1/600], global_step: 10, lr: 0.000003, acc: 0.027344, norm_edit_dis: 0.292343, CTCLoss: 73.472076, SARLoss: 6.741199, loss: 80.212234, avg_reader_cost: 0.56235 s, avg_batch_cost: 2.18094 s, avg_samples: 128.0, ips: 58.69021 samples/s, eta: 4 days, 3:13:36
观点：看来随机生成句子，识别ocr时，丢失了语义的信息，目前看起来主要是用于识别文字，用于训练backbone部分的特征抽取。


主测试数据集上训练的数据非常好，但是不能经过实践检验，应该是过拟合了.


希望验证，通过加入合成的图片，是否可以提高识别的准确度？
采用的方法是，查看val数据的涉及的所有汉字，然后加到汉字库中（383个，实际加入183的太费人工了），重新生成校验数据，
val.txt的图片，之前训练模型的ctc是0.13 ，加入新的汉字后acc提高到到0.20，

acc

下图
2023/03/07 19:42:59] ppocr INFO: load pretrain successful from /home/aistudio/work/output/v3_chinese_cht_mobil/best_accuracy
[2023/03/07 19:42:59] ppocr INFO: metric in ckpt ***************
[2023/03/07 19:42:59] ppocr INFO: is_float16:False
eval model:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.21s/it]
[2023/03/07 19:43:07] ppocr INFO: metric eval ***************
[2023/03/07 19:43:07] ppocr INFO: acc:0.22105260831025175
[2023/03/07 19:43:07] ppocr INFO: norm_edit_dis:0.8275820946928321
[2023/03/07 19:43:07] ppocr INFO: fps:16.32460649029274

但是还是达不到paddleocr的原始繁体字识别效果acc=0.515

[2023/03/07 19:54:34] ppocr INFO: metric in ckpt ***************
[2023/03/07 19:54:34] ppocr INFO: is_float16:False
eval model:: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:08<00:00,  8.19s/it]
[2023/03/07 19:54:43] ppocr INFO: metric eval ***************
[2023/03/07 19:54:43] ppocr INFO: acc:0.5157894193905874
[2023/03/07 19:54:43] ppocr INFO: norm_edit_dis:0.9203884438106642


生成的数据越多，效果越差，应该是正确的汉字少，过拟合了。

## 目前获的信息
1. 通过切割每个单词的图片，然后训练组合成一个字符串，是可以提高ocr的准确度的，但是需要大量的人工，目前两天的时间大概标注了243个单词，主要是一个一个的拆分。
2. 随机生成图像数据集，非常容易过于饱和，此时在paddle原有的ocr上进行调试，5万条数据，acc 13%，增加了50个左右的字之后，acc提升到20%，生成10
3. 万条数据后，acc的值反而下降到8%，观察结果发现，过拟合的训练，把原来的识别正确的字符，识别到新加的字符上了。
今天大概看了
- 对比学习和gan对抗神经网络的视频
gan用于做字体切换知识储备
对比学习，非常有意思，可以通过无监督学习生成特征，如果我把单个图片的按照字符切割，通过对比学习，可以学习到每张图片的特征向量，
然后通过聚类，找到中心点去确认每个单词的图片特征，快速分校验ocr的问题。

明天要看cc-gan看看能否生成有用的字体。


## 2023-03-08 
今天校验了大概1800多个汉字，然后生成汉字，在标注的300多条数据上微调可以达到37%的成绩，目前看主要的问题还是识别的字少的问题。

今天看了CC-gan对应的论文中提到了font2font的代码，决定先跑起来font2font的代码，目前看生成的训练数据像素质量非常的高，真的不知道图片像素比较低的情况下生成的数据，会不会效果不好。


可以用来通过图像投影的的方向，切割字符使用。
https://blog.csdn.net/Print_lin/article/details/81052497
https://zh.wikipedia.org/wiki/%E5%A4%A7%E6%B4%A5%E7%AE%97%E6%B3%95


## 2023-03-09 
今日进展：font2font调通了，本机训练不行，但是预训练的效果不错，决定采用gan字体生成的方法，转换到对应的字体，然后再训练ocr
可能遇到的问题，现在的字体效果不好，因此需要进行Text Image SR 超分操作。

https://zhuanlan.zhihu.com/p/399570671  TPGSR文字图像超分辨网络

https://arxiv.org/pdf/2106.15368.pdf 
该问题在2015年就在学术上被关注了。

https://github.com/mjq11302010044/TATT  git项目

https://paperswithcode.com/paper/a-text-attention-network-for-spatial